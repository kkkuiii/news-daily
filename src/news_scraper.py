#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÊØèÊó•Êñ∞ÈóªÂØºËßà ‚Äì Ëá™Âä®ÊäìÂèñ + DeepSeek ÁøªËØë + ÂÖ®Êñ∞ÁæéËßÇ HTML
"""
import os, sys, re, datetime, logging, smtplib, feedparser
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from urllib.parse import urlparse
from openai import OpenAI

# ---------- Êó•Âøó ----------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ---------- ÈÇÆ‰ª∂ÈÖçÁΩÆ ----------
EMAIL_CONFIG = {
    'smtp_server': os.getenv('SMTP_SERVER', 'smtp.qq.com'),
    'smtp_port': int(os.getenv('SMTP_PORT', '587')),
    'sender_email': os.getenv('SENDER_EMAIL', ''),
    'sender_password': os.getenv('SENDER_PASSWORD', ''),
    'receiver_email': os.getenv('RECEIVER_EMAIL', ''),
}

# ---------- ÊäìÂèñÂô® ----------
class EnhancedNewsScraper:
    def __init__(self, deepseek_api_key: str = None):
        # ÂÆåÊï¥ÁöÑÊñ∞ÈóªÊ∫êÈÖçÁΩÆ - ÂõΩÂÜÖÂ§ñÁªìÂêà
        self.rss_sources = [
            # ÂõΩÂÜÖÁßëÊäÄÊñ∞ÈóªÊ∫ê
            'https://36kr.com/feed ',
            'https://www.pingwest.com/feed ',
            'https://www.jiqizhixin.com/rss ',
            'https://www.leiphone.com/rss ',
            'https://tech.sina.com.cn/rss/index.shtml ',
            'https://tech.qq.com/web/rss_xml.htm ',
            'https://www.geekpark.net/rss ',
            
            # ÂõΩÂ§ñÁßëÊäÄÊñ∞ÈóªÊ∫ê
            'https://www.wired.com/feed/rss ',
            'https://techcrunch.com/feed/ ',
            'https://www.theverge.com/rss/index.xml ',
            'https://arstechnica.com/feed/ ',
            'https://www.engadget.com/rss.xml ',
        ]
        self.categories = {
            'ÁßëÊäÄ': ['technology', 'tech', 'ÁßëÊäÄ', 'Êï∞Á†Å', '‰∫íËÅîÁΩë', 'ËΩØ‰ª∂', 'Á°¨‰ª∂', 'ÂàõÊñ∞', 'startup', 'digital', 'internet'],
            'ÈáëËûç': ['finance', 'financial', 'ÈáëËûç', 'ËÇ°Â∏Ç', 'Èì∂Ë°å', 'ÊäïËµÑ', 'ÁªèÊµé', 'market', 'economy', 'stock', 'banking'],
            'AI': ['ai', 'artificial intelligence', '‰∫∫Â∑•Êô∫ËÉΩ', 'Êú∫Âô®Â≠¶‰π†', 'Ê∑±Â∫¶Â≠¶‰π†', 'ÁÆóÊ≥ï', 'ml', 'neural', 'chatgpt', 'Â§ßÊ®°Âûã'],
            'ÊïôËÇ≤': ['education', 'educational', 'ÊïôËÇ≤', 'Â≠¶Ê†°', 'Â§ßÂ≠¶', 'Â≠¶‰π†', 'ÂüπËÆ≠', 'edu', 'university', 'school'],
            'ÂåªÁñó': ['health', 'medical', 'ÂåªÁñó', 'ÂÅ•Â∫∑', 'ÂåªÈô¢', 'ÁñæÁóÖ', 'ËçØÁâ©', 'medicine', 'hospital', 'doctor'],
            'ÁéØ‰øù': ['environment', 'climate', 'ÁéØ‰øù', 'ÁéØÂ¢É', 'Ê∞îÂÄôÂèòÂåñ', 'ÂèØÊåÅÁª≠', 'green', 'sustainability', 'carbon', 'eco'],
            'Ê±ΩËΩ¶': ['car', 'auto', 'Ê±ΩËΩ¶', 'ÁîµÂä®ËΩ¶', 'ÁîµÂä®Ê±ΩËΩ¶', 'tesla', 'ev', 'vehicle'],
            'Ê∏∏Êàè': ['game', 'gaming', 'Ê∏∏Êàè', 'ÁîµÁ´û', 'ÁîµÂ≠êÁ´ûÊäÄ', 'playstation', 'xbox'],
            'Âå∫ÂùóÈìæ': ['blockchain', 'crypto', 'Âå∫ÂùóÈìæ', 'Âä†ÂØÜË¥ßÂ∏Å', 'ÊØîÁâπÂ∏Å', 'ethereum', 'nft'],
        }
        self.articles_by_category = {c: [] for c in self.categories}
        self.processed_urls = set()
        if not deepseek_api_key:
            raise ValueError("DeepSeek API Key is required")
        self.deepseek_client = OpenAI(api_key=deepseek_api_key, base_url="https://api.deepseek.com")
        logger.info("‚úÖ DeepSeek ÂÆ¢Êà∑Á´ØÂàùÂßãÂåñÊàêÂäü")

    # ------------ ÁøªËØë ------------
    def _translate_titles(self, articles: list[dict]) -> list[dict]:
        if not articles:
            return articles
        en_titles = [a["title"] for a in articles]
        prompt = "ËØ∑Â∞Ü‰∏ãÂàóËã±ÊñáÊñ∞ÈóªÊ†áÈ¢òÁøªËØëÊàêÂú∞ÈÅì‰∏≠ÊñáÔºåÊØèË°åÊ†ºÂºèÔºö‰∏≠ÊñáÊ†áÈ¢ò (English Title)\n" + "\n".join(en_titles)
        try:
            rsp = self.deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            lines = [ln.strip() for ln in rsp.choices[0].message.content.strip().splitlines() if ln.strip()]
        except Exception as e:
            logger.warning(f"ÁøªËØëÂ§±Ë¥•: {e}")
            lines = en_titles
        for a, new_line in zip(articles, lines):
            a["title"] = new_line
        return articles

    # ------------ ÊäìÂèñ ------------
    def fetch_news_from_rss(self):
        headers = {'User-Agent': 'Mozilla/5.0'}
        for rss_url in self.rss_sources:
            try:
                feed = feedparser.parse(rss_url, request_headers=headers)
                for entry in feed.entries[:6]:
                    title = getattr(entry, 'title', 'Êó†Ê†áÈ¢ò')
                    link = getattr(entry, 'link', '')
                    summary = getattr(entry, 'summary', '')[:400] + "..."
                    if link and link not in self.processed_urls:
                        self.processed_urls.add(link)
                        is_relevant, cats = self.categorize_article(title, summary)
                        if is_relevant:
                            art = {
                                'title': title.strip(),
                                'url': link.strip(),
                                'summary': summary.strip() or "ÊöÇÊó†ÊëòË¶Å",
                                'publish_date': getattr(entry, 'published', None),
                                'source': urlparse(rss_url).netloc
                            }
                            for c in cats:
                                if not any(a['url'] == link for a in self.articles_by_category[c]):
                                    self.articles_by_category[c].append(art)
            except Exception as e:
                logger.error(f"RSSÂ§±Ë¥• {rss_url}: {e}")

    def categorize_article(self, title: str, content: str):
        full = (title + " " + content).lower()
        match = []
        for c, kw in self.categories.items():
            score = sum(2 if k in title.lower() else 1 for k in kw if k in full)
            if score >= 1:
                match.append(c)
        return bool(match), match

    def remove_duplicates(self):
        for c in self.articles_by_category:
            seen = set()
            self.articles_by_category[c] = [a for a in self.articles_by_category[c] if not (a['url'] in seen or seen.add(a['url']))]

    def scrape_news(self):
        logger.info("üåê ÂºÄÂßãÊäìÂèñÊñ∞Èóª...")
        self.fetch_news_from_rss()
        self.remove_duplicates()
        logger.info("üìà ÊäìÂèñÂÆåÊàê")

    # ------------ ÊëòË¶Å ------------
    def generate_daily_summary(self) -> str:
        titles = []
        stats = []
        for c, arts in self.articles_by_category.items():
            if arts:
                stats.append(f"{c}:{len(arts)}ÁØá")
                titles += [f"[{c}] {a['title']}" for a in arts[:10]]
        if not titles:
            return "‰ªäÊó•ÂØºËßàÊëòË¶ÅÔºöÊöÇÊó†Êñ∞Èóª„ÄÇ"
        titles_text = "\n".join(titles[:60])
        stats_text = ", ".join(stats)
        prompt = f"""ËØ∑Âü∫‰∫é‰ª•‰∏ãÊñ∞ÈóªÊ†áÈ¢òÁîüÊàê400-600Â≠ó‰∏≠ÊñáÊëòË¶ÅÔºåË¶ÅÊ±ÇÊ¶ÇÊã¨Ë∂ãÂäø„ÄÅÁÑ¶ÁÇπÔºå‰ª•‚Äú‰ªäÊó•ÂØºËßàÊëòË¶ÅÔºö‚ÄùÂºÄÂ§¥„ÄÇ
ÁªüËÆ°Ôºö{stats_text}
Ê†áÈ¢òÔºö
{titles_text}"""
        try:
            rsp = self.deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=1000
            )
            s = rsp.choices[0].message.content.strip()
            return s if s.startswith("‰ªäÊó•ÂØºËßàÊëòË¶ÅÔºö") else "‰ªäÊó•ÂØºËßàÊëòË¶ÅÔºö" + s
        except Exception as e:
            return f"‰ªäÊó•ÂØºËßàÊëòË¶ÅÔºöDeepSeek Ë∞ÉÁî®Â§±Ë¥• - {e}"

    # ------------ ÂÖ®Êñ∞ HTML ------------
    def generate_html_report(self) -> str:
        cur_date = datetime.datetime.now().strftime("%Y-%m-%d")
        cur_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        summary = self.generate_daily_summary()
        cat_counts = [(c, len(a)) for c, a in self.articles_by_category.items() if a]
        cat_counts.sort(key=lambda x: x[1], reverse=True)

        html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>ÊØèÊó•Êñ∞ÈóªÂØºËßà - {cur_date}</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    :root{{--bg:#f4f7fa;--card:#ffffff;--primary:#0d6efd;--secondary:#6c757d;--accent:#ff7f50;--line:#e6e9ef;--text:#212529;--small:#6c757d}}
    body{{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif;background:var(--bg);color:var(--text);line-height:1.6}}
    .container{{max-width:840px;margin:30px auto;padding:0 16px}}
    header{{text-align:center;margin-bottom:40px}}
    .date{{font-size:14px;color:var(--small);margin-bottom:8px}}
    h1{{font-size:32px;margin:0 0 8px}}
    .summary{{background:var(--card);border-left:4px solid var(--primary);padding:24px;border-radius:8px;box-shadow:0 2px 6px rgba(0,0,0,.05);margin-bottom:40px}}
    .summary h2{{margin:0 0 12px;font-size:20px}}
    .category{{margin-bottom:32px}}
    .category h2{{font-size:22px;margin:0 0 16px;display:flex;align-items:center}}
    .category h2 .count{{font-size:14px;margin-left:10px;background:var(--primary);color:#fff;padding:4px 10px;border-radius:12px}}
    .article-list{{display:grid;gap:14px}}
    .article{{background:var(--card);padding:20px;border-radius:8px;box-shadow:0 1px 3px rgba(0,0,0,.06);transition:transform .2s,box-shadow .2s}}
    .article:hover{{transform:translateY(-2px);box-shadow:0 4px 12px rgba(0,0,0,.08)}}
    .article a{{text-decoration:none;color:var(--text);font-weight:600;font-size:16px}}
    .article a:hover{{color:var(--primary)}}
    .meta{{font-size:13px;color:var(--small);margin-top:6px}}
    .summary-text{{font-size:14px;color:var(--small);margin-top:10px;display:-webkit-box;-webkit-line-clamp:2;-webkit-box-orient:vertical;overflow:hidden}}
    .stats{{background:var(--card);padding:20px;border-radius:8px;text-align:center;font-size:14px;color:var(--small)}}
    footer{{text-align:center;font-size:13px;color:var(--small);margin:40px 0 20px}}
    @media(max-width:600px){{h1{{font-size:24px}}.article a{{font-size:15px}}}}
  </style>
</head>
<body>
  <div class="container">
    <header>
      <div class="date">{cur_date} ¬∑ ÊØèÊó•Êñ∞ÈóªÂØºËßà</div>
      <h1>üì∞ ‰ªäÊó•Êñ∞ÈóªÈÄüËßà</h1>
    </header>

    <div class="summary">
      <h2>üéØ ‰ªäÊó•ÂØºËßàÊëòË¶Å</h2>
      <p>{summary}</p>
    </div>"""

        for c, cnt in cat_counts:
            arts = self._translate_titles(self.articles_by_category[c])
            html += f'<div class="category"><h2>{c}<span class="count">{cnt}</span></h2><div class="article-list">'
            for a in arts:
                title = a['title'][:80] + "‚Ä¶" if len(a['title']) > 80 else a['title']
                pub = str(a.get('publish_date') or '')[:16]
                src = a['source']
                summ = re.sub('<[^<]+?>', '', a.get('summary', '') or "ÊöÇÊó†ÊëòË¶Å")[:120] + "‚Ä¶"
                html += f"""
<div class="article">
  <a href="{a['url']}" target="_blank">{title}</a>
  <div class="meta">üïê {pub} ¬∑ üì∞ {src}</div>
  <div class="summary-text">üìù {summ}</div>
</div>"""
            html += '</div></div>'

        total = sum(len(a) for a in self.articles_by_category.values())
        html += f'<div class="stats">ÂÖ±Êî∂ÂΩï <strong>{total}</strong> ÁØáÊñáÁ´† ¬∑ Ê∂µÁõñ <strong>{len(cat_counts)}</strong> ‰∏™È¢ÜÂüü ¬∑ Ëá™Âä®ÁîüÊàê‰∫é {cur_time}</div>'
        html += f'<footer>Powered by DeepSeek AI ¬∑ {cur_time}</footer></div></body></html>'
        return html

# ---------- ÈÇÆ‰ª∂ ----------
class EmailSender:
    @staticmethod
    def send_html_email(html: str, subject: str = None, config: dict = None) -> bool:
        cfg = config or EMAIL_CONFIG
        if not all(cfg.get(k) for k in ('sender_email', 'sender_password', 'receiver_email')):
            logger.error("‚ùå ÈÇÆ‰ª∂ÈÖçÁΩÆ‰∏çÂÆåÊï¥")
            return False
        subject = subject or f"ÊØèÊó•Êñ∞ÈóªÂØºËßà-{datetime.datetime.now().strftime('%Y-%m-%d')}"
        try:
            msg = MIMEMultipart('alternative')
            msg['From'] = cfg['sender_email']
            msg['To'] = cfg['receiver_email']
            msg['Subject'] = Header(subject, 'utf-8')
            msg.attach(MIMEText(html, 'html', 'utf-8'))
            with smtplib.SMTP(cfg['smtp_server'], cfg['smtp_port']) as srv:
                srv.starttls()
                srv.login(cfg['sender_email'], cfg['sender_password'])
                srv.send_message(msg)
            logger.info("‚úÖ ÈÇÆ‰ª∂ÂèëÈÄÅÊàêÂäü")
            return True
        except Exception as e:
            logger.error(f"‚ùå ÈÇÆ‰ª∂ÂèëÈÄÅÂ§±Ë¥•: {e}")
            return False

# ---------- main ----------
def main():
    logger.info("üöÄ ÂºÄÂßãÊñ∞ÈóªÊó•Êä•‰ªªÂä°...")
    DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
    SENDER_EMAIL = os.getenv('SENDER_EMAIL')
    SENDER_PASSWORD = os.getenv('SENDER_PASSWORD')
    RECEIVER_EMAIL = os.getenv('RECEIVER_EMAIL')
    if not DEEPSEEK_API_KEY:
        logger.error("‚ùå ËØ∑ËÆæÁΩÆ DEEPSEEK_API_KEY")
        sys.exit(1)
    if not all([SENDER_EMAIL, SENDER_PASSWORD, RECEIVER_EMAIL]):
        logger.error("‚ùå ËØ∑ËÆæÁΩÆÂÆåÊï¥ÈÇÆ‰ª∂ÁéØÂ¢ÉÂèòÈáè")
        sys.exit(1)
    EMAIL_CONFIG.update({
        'sender_email': SENDER_EMAIL,
        'sender_password': SENDER_PASSWORD,
        'receiver_email': RECEIVER_EMAIL,
    })
    try:
        scraper = EnhancedNewsScraper(DEEPSEEK_API_KEY)
        scraper.scrape_news()
        html = scraper.generate_html_report()
        with open('/tmp/news_report.html', 'w', encoding='utf-8') as f:
            f.write(html)
        EmailSender.send_html_email(html)
    except Exception as e:
        logger.error(f"‚ùå ÊâßË°åÂá∫Èîô: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()
