import newspaper
from datetime import datetime
import time
import logging
import os
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
import sys

# DeepSeek é›†æˆ
from openai import OpenAI

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é‚®ä»¶é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
EMAIL_CONFIG = {
    'smtp_server': os.getenv('SMTP_SERVER', 'smtp.qq.com'),
    'smtp_port': int(os.getenv('SMTP_PORT', '587')),
    'sender_email': os.getenv('SENDER_EMAIL', ''),
    'sender_password': os.getenv('SENDER_PASSWORD', ''),
    'receiver_email': os.getenv('RECEIVER_EMAIL', ''),
}

class NewsScraper:
    def __init__(self, deepseek_api_key: str = None):
        # æ–°é—»æºé…ç½®
        self.news_sources = [
            'https://www.36kr.com',
            'https://www.pingwest.com',
            'https://www.jiqizhixin.com',
            'https://www.wired.com',
            'https://techcrunch.com',
        ]
        
        # åˆ†ç±»é…ç½®
        self.categories = {
            'ç§‘æŠ€': ['technology', 'tech', 'ç§‘æŠ€', 'æ•°ç ', 'äº’è”ç½‘', 'è½¯ä»¶', 'ç¡¬ä»¶'],
            'AI': ['ai', 'artificial intelligence', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç®—æ³•'],
            'åŒ»ç–—': ['health', 'medical', 'åŒ»ç–—', 'å¥åº·', 'åŒ»é™¢', 'ç–¾ç—…'],
        }
        
        # å­˜å‚¨ç»“æœ
        self.articles_by_category = {category: [] for category in self.categories.keys()}
        self.processed_urls = set()
        
        # åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
        self.deepseek_client = None
        if deepseek_api_key:
            try:
                self.deepseek_client = OpenAI(
                    api_key=deepseek_api_key,
                    base_url="https://api.deepseek.com"
                )
                logger.info("âœ… DeepSeek API å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ DeepSeek API å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def get_news_source(self, source_url: str) -> newspaper.Source:
        """è·å–æ–°é—»æº"""
        try:
            config = {
                'memoize_articles': False,
                'request_timeout': 15,
                'browser_user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            }
            
            source = newspaper.build(source_url, **config)
            logger.info(f"âœ… æˆåŠŸåŠ è½½æ–°é—»æº: {source_url} (æ–‡ç« æ•°: {len(source.articles)})")
            return source
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ–°é—»æºå¤±è´¥ {source_url}: {e}")
            return None
    
    def is_article_relevant(self, article) -> tuple:
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦åŒ…å«å…³é”®è¯"""
        try:
            if article.url in self.processed_urls:
                return False, []
            
            self.processed_urls.add(article.url)
            
            article.download()
            if not article.download_state == 2:
                return False, []
                
            article.parse()
            
            title = article.title.lower() if article.title else ""
            text = article.text.lower() if article.text else ""
            content = title + " " + text[:1000]
            
            if len(content) < 30:
                return False, []
            
            relevant_categories = []
            
            for category, keywords in self.categories.items():
                match_score = 0
                for keyword in keywords:
                    if keyword.lower() in content:
                        match_score += 1
                        if keyword.lower() in title:
                            match_score += 2
                
                threshold = 1 if keyword.lower() in title else 2
                if match_score >= threshold:
                    relevant_categories.append(category)
            
            return len(relevant_categories) > 0, relevant_categories
            
        except Exception as e:
            logger.debug(f"å¤„ç†æ–‡ç« æ—¶å‡ºé”™: {e}")
            return False, []
    
    def scrape_news(self, max_articles_per_source: int = 6):
        """æŠ“å–æ–°é—»"""
        successful_sources = 0
        total_processed = 0
        
        for source_url in self.news_sources:
            logger.info(f"ğŸ“¡ æ­£åœ¨å¤„ç†æ–°é—»æº: {source_url}")
            
            source = self.get_news_source(source_url)
            if not source or len(source.articles) == 0:
                logger.warning(f"âš ï¸ æ–°é—»æº {source_url} æ²¡æœ‰å¯å¤„ç†çš„æ–‡ç« ")
                continue
            
            articles_to_process = source.articles[:max_articles_per_source]
            processed_count = 0
            
            for article in articles_to_process:
                try:
                    is_relevant, categories = self.is_article_relevant(article)
                    
                    if is_relevant:
                        article_data = {
                            'title': article.title.strip() if article.title else "æ— æ ‡é¢˜",
                            'url': article.url,
                            'publish_date': article.publish_date,
                            'summary': (article.summary[:150] + "...") if article.summary else ""
                        }
                        
                        for category in categories:
                            if not any(a['url'] == article.url for a in self.articles_by_category[category]):
                                self.articles_by_category[category].append(article_data)
                        
                        logger.info(f"ğŸ¯ æ‰¾åˆ°ç›¸å…³æ–‡ç« : {article.title[:50]}...")
                        processed_count += 1
                        total_processed += 1                     
                    time.sleep(0.2)
                    
                except Exception as e:
                    logger.debug(f"å¤„ç†æ–‡ç« æ—¶å‡ºé”™ {article.url}: {e}")
                    continue
            
            if processed_count > 0:
                successful_sources += 1
            logger.info(f"ğŸ“Š ä» {source_url} å¤„ç†äº† {processed_count} ç¯‡ç›¸å…³æ–‡ç« ")
        
        logger.info(f"ğŸ“ˆ æ€»ç»“: å¤„ç†äº† {successful_sources} ä¸ªæ–°é—»æºï¼Œå…±æ‰¾åˆ° {total_processed} ç¯‡ç›¸å…³æ–‡ç« ")
    
    def remove_duplicates(self):
        """å»é™¤é‡å¤æ–‡ç« """
        total_before = sum(len(articles) for articles in self.articles_by_category.values())
        
        for category in self.articles_by_category:
            seen_urls = set()
            unique_articles = []
            
            for article in self.articles_by_category[category]:
                if article['url'] not in seen_urls:
                    seen_urls.add(article['url'])
                    unique_articles.append(article)
            
            self.articles_by_category[category] = unique_articles
        
        total_after = sum(len(articles) for articles in self.articles_by_category.values())
        logger.info(f"ğŸ—‘ï¸ å»é‡å®Œæˆ: {total_before} â†’ {total_after} ç¯‡æ–‡ç« ")
    
    def generate_daily_summary(self) -> str:
        """ä½¿ç”¨ DeepSeek ç”Ÿæˆä»Šæ—¥æ–°é—»æ‘˜è¦"""
        if not self.deepseek_client:
            return "âš ï¸ æœªé…ç½® DeepSeek APIï¼Œæ— æ³•ç”Ÿæˆæ™ºèƒ½æ‘˜è¦ã€‚"
        
        try:
            all_titles = []
            category_stats = {}
            
            for category, articles in self.articles_by_category.items():
                if articles:
                    category_stats[category] = len(articles)
                    for article in articles[:6]:
                        all_titles.append(f"[{category}] {article['title']}")
            
            if not all_titles:
                return "ğŸ“° ä»Šæ—¥æš‚æ— ç›¸å…³æ–°é—»å†…å®¹ã€‚"
            
            titles_text = "\n".join(all_titles[:30])
            stats_text = ", ".join([f"{cat}:{count}ç¯‡" for cat, count in category_stats.items()])
            
            prompt = f"""
            è¯·åŸºäºä»¥ä¸‹ä»Šæ—¥æ–°é—»æ ‡é¢˜ï¼Œç”Ÿæˆä¸€æ®µ300-400å­—çš„ä¸­æ–‡æ‘˜è¦ã€‚è¦æ±‚ï¼š
            1. ä¸è¦æœºæ¢°å¤è¿°æ ‡é¢˜ï¼Œè¦è¿›è¡Œæ¦‚æ‹¬ä¸ä¸²è”
            2. æç‚¼å‡ºå½“æ—¥æ–°é—»çš„ä¸»è¦è¶‹åŠ¿ã€å…³æ³¨ç„¦ç‚¹
            3. é£æ ¼è‡ªç„¶æµç•…ï¼Œå…·æœ‰æ•´ä½“æ„Ÿ
            4. çªå‡ºæœ€é‡è¦çš„å‡ ä¸ªä¸»é¢˜æ–¹å‘
            
            ä»Šæ—¥æ–°é—»ç»Ÿè®¡ï¼š{stats_text}
            
            æ–°é—»æ ‡é¢˜åˆ—è¡¨ï¼š
            {titles_text}
            
            è¯·ä»¥"ä»Šæ—¥å¯¼è§ˆæ‘˜è¦ï¼š"å¼€å¤´ï¼Œç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ã€‚
            """
            
            logger.info("ğŸ¤– æ­£åœ¨è°ƒç”¨ DeepSeek ç”Ÿæˆæ™ºèƒ½æ‘˜è¦...")
            
            response = self.deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–°é—»åˆ†æå¸ˆï¼Œæ“…é•¿æ€»ç»“å’Œåˆ†ææ–°é—»è¶‹åŠ¿ã€‚"},
                    {"role": "user", "content": prompt},
                ],
                stream=False,
                temperature=0.7,
                max_tokens=600
            )
            
            summary = response.choices[0].message.content.strip()
            if not summary.startswith("ä»Šæ—¥å¯¼è§ˆæ‘˜è¦ï¼š"):
                summary = "ä»Šæ—¥å¯¼è§ˆæ‘˜è¦ï¼š" + summary
            
            logger.info("âœ… DeepSeek æ‘˜è¦ç”ŸæˆæˆåŠŸ")
            return summary
            
        except Exception as e:
            error_msg = f"âŒ DeepSeek æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}"
            logger.error(error_msg)
            return "ä»Šæ—¥å¯¼è§ˆæ‘˜è¦ï¼šç”±äºç³»ç»ŸåŸå› ï¼Œæš‚æ— æ³•ç”Ÿæˆæ™ºèƒ½æ‘˜è¦ã€‚"
    
    def generate_html_report(self) -> str:
        """ç”ŸæˆHTMLæ ¼å¼çš„æ—¥æŠ¥"""
        current_date = datetime.now().strftime("%Y-%m-%d")
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # ç”Ÿæˆæ‘˜è¦
        daily_summary = self.generate_daily_summary()
        
        # å»é‡
        self.remove_duplicates()
        
        # æŒ‰æ–‡ç« æ•°é‡æ’åºåˆ†ç±»
        category_article_counts = [(cat, len(articles)) for cat, articles in self.articles_by_category.items() if articles]
        category_article_counts.sort(key=lambda x: x[1], reverse=True)
        
        # HTML æ¨¡æ¿
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ¯æ—¥æ–°é—»å¯¼è§ˆ - {current_date}</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }}
        .container {{
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        header {{
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #eee;
        }}
        h1 {{
            color: #2c3e50;
            margin: 0 0 10px 0;
        }}
        .meta-info {{
            color: #7f8c8d;
            font-size: 14px;
        }}
        .summary {{
            background-color: #fff8e1;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            border-left: 4px solid #ffc107;
        }}
        .category {{
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
        }}
        .category h2 {{
            margin-top: 0;
            color: #2c3e50;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }}
        .article-item {{
            margin: 15px 0;
            padding: 15px;
            background: white;
            border-radius: 6px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }}
        .article-title {{
            font-size: 16px;
            font-weight: 600;
            margin: 0 0 8px 0;
        }}
        .article-title a {{
            color: #3498db;
            text-decoration: none;
        }}
        .article-title a:hover {{
            text-decoration: underline;
        }}
        .article-meta {{
            font-size: 12px;
            color: #7f8c8d;
            margin: 5px 0;
        }}
        .article-summary {{
            font-size: 13px;
            color: #555;
            margin: 8px 0 0 0;
            line-height: 1.5;
        }}
        .stats {{
            background-color: #e8f4f8;
            padding: 15px;
            border-radius: 8px;
            margin-top: 30px;
        }}
        footer {{
            text-align: center;
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid #eee;
            color: #7f8c8d;
            font-size: 12px;
        }}
        @media (max-width: 600px) {{
            .container {{
                padding: 15px;
            }}
            .article-title {{
                font-size: 14px;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸ“° æ¯æ—¥æ–°é—»å¯¼è§ˆ</h1>
            <div class="meta-info">
                ğŸ“… æ—¥æœŸ: {current_date} | ğŸ• ç”Ÿæˆæ—¶é—´: {current_time}
            </div>
        </header>
        
        <div class="summary">
            <h2>ğŸ¯ ä»Šæ—¥å¯¼è§ˆæ‘˜è¦</h2>
            <p>{daily_summary}</p>
        </div>
        
        """
        
        has_content = False
        for category, count in category_article_counts:
            articles = self.articles_by_category[category]
            if articles:
                has_content = True
                html_content += f"""
        <div class="category">
            <h2>ï¿½? {category} ({count}ç¯‡)</h2>
                """
                
                for i, article in enumerate(articles, 1):
                    clean_title = article['title'].replace('[', '').replace(']', '').strip()
                    if len(clean_title) > 60:
                        clean_title = clean_title[:60] + "..."
                    
                    html_content += f"""
            <div class="article-item">
                <div class="article-title">{i}. <a href="{article['url']}" target="_blank">{clean_title}</a></div>
                """
                    
                    if article.get('publish_date'):
                        pub_date = article['publish_date']
                        if isinstance(pub_date, str):
                            html_content += f'<div class="article-meta">ğŸ• å‘å¸ƒæ—¶é—´: {pub_date}</div>\n'
                        elif hasattr(pub_date, 'strftime'):
                            html_content += f'<div class="article-meta">ğŸ• å‘å¸ƒæ—¶é—´: {pub_date.strftime("%Y-%m-%d %H:%M")}</div>\n'
                    
                    if article.get('summary') and len(article['summary']) > 10:
                        html_content += f'<div class="article-summary">ğŸ“ æ‘˜è¦: {article["summary"]}</div>\n'
                    
                    html_content += '            </div>\n'
                
                html_content += '        </div>\n'
        
        if not has_content:
            html_content += """
        <div class="category">
            <h2>âš ï¸ æš‚æ— ç›¸å…³æ–°é—»</h2>
            <p>å½“å‰æ—¶é—´æ®µå†…æœªæ‰¾åˆ°ç¬¦åˆå…³é”®è¯åˆ†ç±»çš„æ–°é—»ã€‚</p>
        </div>
            """
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_articles = sum(len(articles) for articles in self.articles_by_category.values())
        html_content += f"""
        <div class="stats">
            <h2>ğŸ“Š è¯¦ç»†ç»Ÿè®¡</h2>
            <p>- æ€»æ–‡ç« æ•°: {total_articles}</p>
            <p>- æ¶‰åŠåˆ†ç±»: {len([cat for cat, count in category_article_counts if count > 0])}</p>
            <p>- å¤„ç†æ–°é—»æº: {len(self.news_sources)}</p>
        </div>
        
        <footer>
            <p>ğŸ“Š æ–°é—»æ—¥æŠ¥è‡ªåŠ¨ç”Ÿæˆ | ğŸ• ç”Ÿæˆæ—¶é—´: {current_time} | ğŸ¤– Powered by DeepSeek AI</p>
        </footer>
    </div>
</body>
</html>
        """
        
        return html_content

class EmailSender:
    """é‚®ä»¶å‘é€å™¨"""
    
    @staticmethod
    def send_html_email(html_content: str, subject: str = None, config: dict = None) -> bool:
        """å‘é€HTMLé‚®ä»¶"""
        if not config:
            config = EMAIL_CONFIG
        
        if not all([config['sender_email'], config['sender_password'], config['receiver_email']]):
            logger.error("âŒ é‚®ä»¶é…ç½®ä¸å®Œæ•´")
            return False
        
        if not subject:
            subject = f"æ¯æ—¥æ–°é—»å¯¼è§ˆ-{datetime.now().strftime('%Y-%m-%d')}"
        
        try:
            # åˆ›å»ºé‚®ä»¶å¯¹è±¡
            msg = MIMEMultipart('alternative')
            msg['From'] = config['sender_email']
            msg['To'] = config['receiver_email']
            msg['Subject'] = Header(subject, 'utf-8')
            
            # æ·»åŠ HTMLå†…å®¹
            html_part = MIMEText(html_content, 'html', 'utf-8')
            msg.attach(html_part)
            
            # è¿æ¥SMTPæœåŠ¡å™¨å¹¶å‘é€
            server = smtplib.SMTP(config['smtp_server'], config['smtp_port'])
            server.starttls()
            server.login(config['sender_email'], config['sender_password'])
            server.send_message(msg)
            server.quit()
            
            logger.info("âœ… é‚®ä»¶å‘é€æˆåŠŸï¼")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ–°é—»æ—¥æŠ¥ä»»åŠ¡...")
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
    SENDER_EMAIL = os.getenv('SENDER_EMAIL')
    SENDER_PASSWORD = os.getenv('SENDER_PASSWORD')
    RECEIVER_EMAIL = os.getenv('RECEIVER_EMAIL')
    
    if not all([DEEPSEEK_API_KEY, SENDER_EMAIL, SENDER_PASSWORD, RECEIVER_EMAIL]):
        logger.error("âŒ ç¯å¢ƒå˜é‡é…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ GitHub Secrets è®¾ç½®")
        sys.exit(1)
    
    # æ›´æ–°é‚®ä»¶é…ç½®
    global EMAIL_CONFIG
    EMAIL_CONFIG.update({
        'sender_email': SENDER_EMAIL,
        'sender_password': SENDER_PASSWORD,
        'receiver_email': RECEIVER_EMAIL,
    })
    
    try:
        # åˆ›å»ºæ–°é—»æŠ“å–å™¨
        scraper = NewsScraper(deepseek_api_key=DEEPSEEK_API_KEY)
        
        # å¼€å§‹æŠ“å–æ–°é—»
        logger.info("ğŸŒ å¼€å§‹æŠ“å–æ–°é—»...")
        scraper.scrape_news(max_articles_per_source=5)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_content = scraper.generate_html_report()
        logger.info("ğŸ‰ æ–°é—»æ—¥æŠ¥ç”Ÿæˆå®Œæˆ!")
        
        # å‘é€é‚®ä»¶
        email_sent = EmailSender.send_html_email(
            html_content=html_content,
            subject=f"æ¯æ—¥æ–°é—»å¯¼è§ˆ-{datetime.now().strftime('%Y-%m-%d')}",
            config=EMAIL_CONFIG
        )
        
        if email_sent:
            logger.info("ğŸ“§ é‚®ä»¶å‘é€æˆåŠŸï¼")
        else:
            logger.error("ğŸ“§ é‚®ä»¶å‘é€å¤±è´¥ï¼")
            
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
