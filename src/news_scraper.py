#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥æ–°é—»å¯¼è§ˆ â€“ è‡ªåŠ¨æŠ“å– + DeepSeek ç¿»è¯‘ + å…¨æ–°ç¾è§‚ HTML
"""
import os, sys, re, datetime, logging, smtplib, feedparser
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from urllib.parse import urlparse
from openai import OpenAI

# ---------- æ—¥å¿— ----------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ---------- é‚®ä»¶é…ç½® ----------
EMAIL_CONFIG = {
    'smtp_server': os.getenv('SMTP_SERVER', 'smtp.qq.com'),
    'smtp_port': int(os.getenv('SMTP_PORT', '587')),
    'sender_email': os.getenv('SENDER_EMAIL', ''),
    'sender_password': os.getenv('SENDER_PASSWORD', ''),
    'receiver_email': os.getenv('RECEIVER_EMAIL', ''),
}

# ---------- æŠ“å–å™¨ ----------
class EnhancedNewsScraper:
    def __init__(self, deepseek_api_key: str = None):
        # å®Œæ•´çš„æ–°é—»æºé…ç½® - å›½å†…å¤–ç»“åˆ
        self.rss_sources = [
            # å›½å†…ç§‘æŠ€æ–°é—»æº
            'https://36kr.com/feed ',
            'https://www.pingwest.com/feed ',
            'https://www.jiqizhixin.com/rss ',
            'https://www.leiphone.com/rss ',
            'https://tech.sina.com.cn/rss/index.shtml ',
            'https://tech.qq.com/web/rss_xml.htm ',
            'https://www.geekpark.net/rss ',
            
            # å›½å¤–ç§‘æŠ€æ–°é—»æº
            'https://www.wired.com/feed/rss ',
            'https://techcrunch.com/feed/ ',
            'https://www.theverge.com/rss/index.xml ',
            'https://arstechnica.com/feed/ ',
            'https://www.engadget.com/rss.xml ',
        ]
        self.categories = {
            'ç§‘æŠ€': ['technology', 'tech', 'ç§‘æŠ€', 'æ•°ç ', 'äº’è”ç½‘', 'è½¯ä»¶', 'ç¡¬ä»¶', 'åˆ›æ–°', 'startup', 'digital', 'internet'],
            'é‡‘è': ['finance', 'financial', 'é‡‘è', 'è‚¡å¸‚', 'é“¶è¡Œ', 'æŠ•èµ„', 'ç»æµ', 'market', 'economy', 'stock', 'banking'],
            'AI': ['ai', 'artificial intelligence', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç®—æ³•', 'ml', 'neural', 'chatgpt', 'å¤§æ¨¡å‹'],
            'æ•™è‚²': ['education', 'educational', 'æ•™è‚²', 'å­¦æ ¡', 'å¤§å­¦', 'å­¦ä¹ ', 'åŸ¹è®­', 'edu', 'university', 'school'],
            'åŒ»ç–—': ['health', 'medical', 'åŒ»ç–—', 'å¥åº·', 'åŒ»é™¢', 'ç–¾ç—…', 'è¯ç‰©', 'medicine', 'hospital', 'doctor'],
            'ç¯ä¿': ['environment', 'climate', 'ç¯ä¿', 'ç¯å¢ƒ', 'æ°”å€™å˜åŒ–', 'å¯æŒç»­', 'green', 'sustainability', 'carbon', 'eco'],
            'æ±½è½¦': ['car', 'auto', 'æ±½è½¦', 'ç”µåŠ¨è½¦', 'ç”µåŠ¨æ±½è½¦', 'tesla', 'ev', 'vehicle'],
            'æ¸¸æˆ': ['game', 'gaming', 'æ¸¸æˆ', 'ç”µç«', 'ç”µå­ç«æŠ€', 'playstation', 'xbox'],
            'åŒºå—é“¾': ['blockchain', 'crypto', 'åŒºå—é“¾', 'åŠ å¯†è´§å¸', 'æ¯”ç‰¹å¸', 'ethereum', 'nft'],
        }
        self.articles_by_category = {c: [] for c in self.categories}
        self.processed_urls = set()
        if not deepseek_api_key:
            raise ValueError("DeepSeek API Key is required")
        self.deepseek_client = OpenAI(api_key=deepseek_api_key, base_url="https://api.deepseek.com")
        logger.info("âœ… DeepSeek å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

    # ------------ ç¿»è¯‘ ------------
    def _translate_titles(self, articles: list[dict]) -> list[dict]:
        if not articles:
            return articles
        en_titles = [a["title"] for a in articles]
        prompt = "è¯·å°†ä¸‹åˆ—è‹±æ–‡æ–°é—»æ ‡é¢˜ç¿»è¯‘æˆåœ°é“ä¸­æ–‡ï¼Œæ¯è¡Œæ ¼å¼ï¼šä¸­æ–‡æ ‡é¢˜ (English Title)\n" + "\n".join(en_titles)
        try:
            rsp = self.deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            lines = [ln.strip() for ln in rsp.choices[0].message.content.strip().splitlines() if ln.strip()]
        except Exception as e:
            logger.warning(f"ç¿»è¯‘å¤±è´¥: {e}")
            lines = en_titles
        for a, new_line in zip(articles, lines):
            a["title"] = new_line
        return articles

    # ------------ æŠ“å– ------------
    def fetch_news_from_rss(self):
        headers = {'User-Agent': 'Mozilla/5.0'}
        for rss_url in self.rss_sources:
            try:
                feed = feedparser.parse(rss_url, request_headers=headers)
                for entry in feed.entries[:6]:
                    title = getattr(entry, 'title', 'æ— æ ‡é¢˜')
                    link = getattr(entry, 'link', '')
                    summary = getattr(entry, 'summary', '')[:400] + "..."
                    if link and link not in self.processed_urls:
                        self.processed_urls.add(link)
                        is_relevant, cats = self.categorize_article(title, summary)
                        if is_relevant:
                            art = {
                                'title': title.strip(),
                                'url': link.strip(),
                                'summary': summary.strip() or "æš‚æ— æ‘˜è¦",
                                'publish_date': getattr(entry, 'published', None),
                                'source': urlparse(rss_url).netloc
                            }
                            for c in cats:
                                if not any(a['url'] == link for a in self.articles_by_category[c]):
                                    self.articles_by_category[c].append(art)
            except Exception as e:
                logger.error(f"RSSå¤±è´¥ {rss_url}: {e}")

    def categorize_article(self, title: str, content: str):
        full = (title + " " + content).lower()
        match = []
        for c, kw in self.categories.items():
            score = sum(2 if k in title.lower() else 1 for k in kw if k in full)
            if score >= 1:
                match.append(c)
        return bool(match), match

    def remove_duplicates(self):
        for c in self.articles_by_category:
            seen = set()
            self.articles_by_category[c] = [a for a in self.articles_by_category[c] if not (a['url'] in seen or seen.add(a['url']))]

    def scrape_news(self):
        logger.info("ğŸŒ å¼€å§‹æŠ“å–æ–°é—»...")
        self.fetch_news_from_rss()
        self.remove_duplicates()
        logger.info("ğŸ“ˆ æŠ“å–å®Œæˆ")

    # ------------ æ‘˜è¦ ------------
    def generate_daily_summary(self) -> str:
        titles = []
        stats = []
        for c, arts in self.articles_by_category.items():
            if arts:
                stats.append(f"{c}:{len(arts)}ç¯‡")
                titles += [f"[{c}] {a['title']}" for a in arts[:10]]
        if not titles:
            return "ä»Šæ—¥å¯¼è§ˆæ‘˜è¦ï¼šæš‚æ— æ–°é—»ã€‚"
        titles_text = "\n".join(titles[:60])
        stats_text = ", ".join(stats)
        prompt = f"""è¯·åŸºäºä»¥ä¸‹æ–°é—»æ ‡é¢˜ç”Ÿæˆ400-600å­—ä¸­æ–‡æ‘˜è¦ï¼Œè¦æ±‚æ¦‚æ‹¬è¶‹åŠ¿ã€ç„¦ç‚¹ï¼Œä»¥â€œä»Šæ—¥å¯¼è§ˆæ‘˜è¦ï¼šâ€å¼€å¤´ã€‚
ç»Ÿè®¡ï¼š{stats_text}
æ ‡é¢˜ï¼š
{titles_text}"""
        try:
            rsp = self.deepseek_client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=1000
            )
            s = rsp.choices[0].message.content.strip()
            return s if s.startswith("ä»Šæ—¥å¯¼è§ˆæ‘˜è¦ï¼š") else "ä»Šæ—¥å¯¼è§ˆæ‘˜è¦ï¼š" + s
        except Exception as e:
            return f"ä»Šæ—¥å¯¼è§ˆæ‘˜è¦ï¼šDeepSeek è°ƒç”¨å¤±è´¥ - {e}"

    # ------------ å…¨æ–° HTML ------------
    def generate_html_report(self) -> str:
        cur_date = datetime.datetime.now().strftime("%Y-%m-%d")
        cur_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        summary = self.generate_daily_summary()
        cat_counts = [(c, len(a)) for c, a in self.articles_by_category.items() if a]
        cat_counts.sort(key=lambda x: x[1], reverse=True)

        html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>æ¯æ—¥æ–°é—»å¯¼è§ˆ - {cur_date}</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    :root{{--bg:#f4f7fa;--card:#ffffff;--primary:#0d6efd;--secondary:#6c757d;--accent:#ff7f50;--line:#e6e9ef;--text:#212529;--small:#6c757d}}
    body{{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif;background:var(--bg);color:var(--text);line-height:1.6}}
    .container{{max-width:840px;margin:30px auto;padding:0 16px}}
    header{{text-align:center;margin-bottom:40px}}
    .date{{font-size:14px;color:var(--small);margin-bottom:8px}}
    h1{{font-size:32px;margin:0 0 8px}}
    .summary{{background:var(--card);border-left:4px solid var(--primary);padding:24px;border-radius:8px;box-shadow:0 2px 6px rgba(0,0,0,.05);margin-bottom:40px}}
    .summary h2{{margin:0 0 12px;font-size:20px}}
    .category{{margin-bottom:32px}}
    .category h2{{font-size:22px;margin:0 0 16px;display:flex;align-items:center}}
    .category h2 .count{{font-size:14px;margin-left:10px;background:var(--primary);color:#fff;padding:4px 10px;border-radius:12px}}
    .article-list{{display:grid;gap:14px}}
    .article{{background:var(--card);padding:20px;border-radius:8px;box-shadow:0 1px 3px rgba(0,0,0,.06);transition:transform .2s,box-shadow .2s}}
    .article:hover{{transform:translateY(-2px);box-shadow:0 4px 12px rgba(0,0,0,.08)}}
    .article a{{text-decoration:none;color:var(--text);font-weight:600;font-size:16px}}
    .article a:hover{{color:var(--primary)}}
    .meta{{font-size:13px;color:var(--small);margin-top:6px}}
    .summary-text{{font-size:14px;color:var(--small);margin-top:10px;display:-webkit-box;-webkit-line-clamp:2;-webkit-box-orient:vertical;overflow:hidden}}
    .stats{{background:var(--card);padding:20px;border-radius:8px;text-align:center;font-size:14px;color:var(--small)}}
    footer{{text-align:center;font-size:13px;color:var(--small);margin:40px 0 20px}}
    @media(max-width:600px){{h1{{font-size:24px}}.article a{{font-size:15px}}}}
  </style>
</head>
<body>
  <div class="container">
    <header>
      <div class="date">{cur_date} Â· æ¯æ—¥æ–°é—»å¯¼è§ˆ</div>
      <h1>ğŸ“° ä»Šæ—¥æ–°é—»é€Ÿè§ˆ</h1>
    </header>

    <div class="summary">
      <h2>ğŸ¯ ä»Šæ—¥å¯¼è§ˆæ‘˜è¦</h2>
      <p>{summary}</p>
    </div>"""

        for c, cnt in cat_counts:
            arts = self._translate_titles(self.articles_by_category[c])
            html += f'<div class="category"><h2>{c}<span class="count">{cnt}</span></h2><div class="article-list">'
            for a in arts:
                title = a['title'][:80] + "â€¦" if len(a['title']) > 80 else a['title']
                pub = str(a.get('publish_date') or '')[:16]
                src = a['source']
                summ = re.sub('<[^<]+?>', '', a.get('summary', '') or "æš‚æ— æ‘˜è¦")[:120] + "â€¦"
                html += f"""
<div class="article">
  <a href="{a['url']}" target="_blank">{title}</a>
  <div class="meta">ğŸ• {pub} Â· ğŸ“° {src}</div>
  <div class="summary-text">ğŸ“ {summ}</div>
</div>"""
            html += '</div></div>'

        total = sum(len(a) for a in self.articles_by_category.values())
        html += f'<div class="stats">å…±æ”¶å½• <strong>{total}</strong> ç¯‡æ–‡ç«  Â· æ¶µç›– <strong>{len(cat_counts)}</strong> ä¸ªé¢†åŸŸ Â· è‡ªåŠ¨ç”Ÿæˆäº {cur_time}</div>'
        html += f'<footer>Powered by DeepSeek AI Â· {cur_time}</footer></div></body></html>'
        return html

# ---------- é‚®ä»¶ ----------
class EmailSender:
    @staticmethod
    def send_html_email(html: str, subject: str = None, config: dict = None) -> bool:
        cfg = config or EMAIL_CONFIG
        if not all(cfg.get(k) for k in ('sender_email', 'sender_password', 'receiver_email')):
            logger.error("âŒ é‚®ä»¶é…ç½®ä¸å®Œæ•´")
            return False
        subject = subject or f"æ¯æ—¥æ–°é—»å¯¼è§ˆ-{datetime.datetime.now().strftime('%Y-%m-%d')}"
        try:
            msg = MIMEMultipart('alternative')
            msg['From'] = cfg['sender_email']
            msg['To'] = cfg['receiver_email']
            msg['Subject'] = Header(subject, 'utf-8')
            msg.attach(MIMEText(html, 'html', 'utf-8'))
            with smtplib.SMTP(cfg['smtp_server'], cfg['smtp_port']) as srv:
                srv.starttls()
                srv.login(cfg['sender_email'], cfg['sender_password'])
                srv.send_message(msg)
            logger.info("âœ… é‚®ä»¶å‘é€æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")
            return False

# ---------- main ----------
def main():
    logger.info("ğŸš€ å¼€å§‹æ–°é—»æ—¥æŠ¥ä»»åŠ¡...")
    DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
    SENDER_EMAIL = os.getenv('SENDER_EMAIL')
    SENDER_PASSWORD = os.getenv('SENDER_PASSWORD')
    RECEIVER_EMAIL = os.getenv('RECEIVER_EMAIL')
    if not DEEPSEEK_API_KEY:
        logger.error("âŒ è¯·è®¾ç½® DEEPSEEK_API_KEY")
        sys.exit(1)
    if not all([SENDER_EMAIL, SENDER_PASSWORD, RECEIVER_EMAIL]):
        logger.error("âŒ è¯·è®¾ç½®å®Œæ•´é‚®ä»¶ç¯å¢ƒå˜é‡")
        sys.exit(1)
    EMAIL_CONFIG.update({
        'sender_email': SENDER_EMAIL,
        'sender_password': SENDER_PASSWORD,
        'receiver_email': RECEIVER_EMAIL,
    })
    try:
        scraper = EnhancedNewsScraper(DEEPSEEK_API_KEY)
        scraper.scrape_news()
        html = scraper.generate_html_report()
        with open('/tmp/news_report.html', 'w', encoding='utf-8') as f:
            f.write(html)
        EmailSender.send_html_email(html)
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()
